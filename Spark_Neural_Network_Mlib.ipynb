{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8nWkEXvFQlBt56SmHJVL9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nestorpereiralinares/PySpark-ML/blob/main/Spark_Neural_Network_Mlib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "awUT3ks8JL2L"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "# java and enviroment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train neural network. MultilayerPerceptronClassifier**"
      ],
      "metadata": {
        "id": "kog-NJ1CM8Kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html"
      ],
      "metadata": {
        "id": "2SkMzNcYLzy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set up spark context and SparkSession**"
      ],
      "metadata": {
        "id": "XVePhKPxJbx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up spark context and SparkSession\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark Feedforward neural network example\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "_W4FB_31JcMo",
        "outputId": "b0261c7c-f61c-4aab-a52a-7d8752f7da94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f35d44c1ee0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8e1014ef3386:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Python Spark Feedforward neural network example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read data\n",
        "# We can set header='true' and inferSchema='true' to infer the schema while reading the data\n",
        "\n",
        "\n",
        "!wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv -P sample_data/\n",
        "\n",
        "filepath = \"sample_data/winequality-red.csv\"\n",
        "df = spark.read.format('csv').options(header='true', inferSchema='true', delimiter=';').load(filepath)\n",
        "df.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIMKir5DJkGT",
        "outputId": "ae47d3bf-8618-445c-a280-462b88047c70"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
            "|fixed acidity|volatile acidity|citric acid|residual sugar|chlorides|free sulfur dioxide|total sulfur dioxide|density|pH  |sulphates|alcohol|quality|\n",
            "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
            "|7.4          |0.7             |0.0        |1.9           |0.076    |11.0               |34.0                |0.9978 |3.51|0.56     |9.4    |5      |\n",
            "|7.8          |0.88            |0.0        |2.6           |0.098    |25.0               |67.0                |0.9968 |3.2 |0.68     |9.8    |5      |\n",
            "|7.8          |0.76            |0.04       |2.3           |0.092    |15.0               |54.0                |0.997  |3.26|0.65     |9.8    |5      |\n",
            "|11.2         |0.28            |0.56       |1.9           |0.075    |17.0               |60.0                |0.998  |3.16|0.58     |9.8    |6      |\n",
            "|7.4          |0.7             |0.0        |1.9           |0.076    |11.0               |34.0                |0.9978 |3.51|0.56     |9.4    |5      |\n",
            "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# functions to change categorical variable size\n",
        "\n",
        "# Convert to float format\n",
        "def string_to_float(x):\n",
        "    return float(x)\n",
        "\n",
        "#\n",
        "def condition(r):\n",
        "    if (0<= r <= 4):\n",
        "        label = \"low\"\n",
        "    elif(4< r <= 6):\n",
        "        label = \"medium\"\n",
        "    else:\n",
        "        label = \"high\"\n",
        "    return label"
      ],
      "metadata": {
        "id": "x2MMapsNJkSx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A1-2jWJYKbTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "duSCCHLOKbhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using functions"
      ],
      "metadata": {
        "id": "N8VDmwz2KMwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType, DoubleType\n",
        "string_to_float_udf = udf(string_to_float, DoubleType())\n",
        "quality_udf = udf(lambda x: condition(x), StringType())\n",
        "df= df.withColumn(\"quality\", quality_udf(\"quality\"))"
      ],
      "metadata": {
        "id": "2izmXiM1KM7s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqQII8fAKNcN",
        "outputId": "f16a2373-6819-4a04-f641-f025d8946184"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[fixed acidity: double, volatile acidity: double, citric acid: double, residual sugar: double, chlorides: double, free sulfur dioxide: double, total sulfur dioxide: double, density: double, pH: double, sulphates: double, alcohol: double, quality: string]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the data to **dense vector**"
      ],
      "metadata": {
        "id": "o4fDmR8rKlXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# convert the data to dense vector\n",
        "def transData(data):\n",
        "    return data.rdd.map(lambda r: [r[-1], Vectors.dense(r[:-1])]).\\\n",
        "           toDF(['label','features'])\n",
        "\n",
        "from pyspark.sql import Row\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "data= transData(df)\n",
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejM_d5WvKhIc",
        "outputId": "e5f424c1-b5bd-4d7f-dbef-c5574dcf3ee2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+\n",
            "| label|            features|\n",
            "+------+--------------------+\n",
            "|medium|[7.4,0.7,0.0,1.9,...|\n",
            "|medium|[7.8,0.88,0.0,2.6...|\n",
            "|medium|[7.8,0.76,0.04,2....|\n",
            "|medium|[11.2,0.28,0.56,1...|\n",
            "|medium|[7.4,0.7,0.0,1.9,...|\n",
            "|medium|[7.4,0.66,0.0,1.8...|\n",
            "|medium|[7.9,0.6,0.06,1.6...|\n",
            "|  high|[7.3,0.65,0.0,1.2...|\n",
            "|  high|[7.8,0.58,0.02,2....|\n",
            "|medium|[7.5,0.5,0.36,6.1...|\n",
            "|medium|[6.7,0.58,0.08,1....|\n",
            "|medium|[7.5,0.5,0.36,6.1...|\n",
            "|medium|[5.6,0.615,0.0,1....|\n",
            "|medium|[7.8,0.61,0.29,1....|\n",
            "|medium|[8.9,0.62,0.18,3....|\n",
            "|medium|[8.9,0.62,0.19,3....|\n",
            "|  high|[8.5,0.28,0.56,1....|\n",
            "|medium|[8.1,0.56,0.28,1....|\n",
            "|   low|[7.4,0.59,0.08,4....|\n",
            "|medium|[7.9,0.32,0.51,1....|\n",
            "+------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into training and test sets (40% held out for testing)"
      ],
      "metadata": {
        "id": "jdS956gVKuLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test\n",
        "(trainingData, testData) = data.randomSplit([0.6, 0.4])\n",
        "\n",
        "# Split the data into train and test"
      ],
      "metadata": {
        "id": "0kGjEd96KuVt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train neural network**.  MultilayerPerceptronClassifier\n",
        "\n",
        "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.MultilayerPerceptronClassifier.html\n",
        "\n",
        "https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html"
      ],
      "metadata": {
        "id": "4xnq1Ue3K6NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.ml.linalg import Vectors\n",
        "# specify layers for the neural network:\n",
        "# input layer of size 11 (features), two intermediate of size 5 and 4\n",
        "# and output of size 7 (classes)\n",
        "\n",
        "layers = [11, 5, 4, 4, 3 , 7]\n",
        "\n",
        "# create the trainer and set its parameters\n",
        "\n",
        "# mlp = MultilayerPerceptronClassifier(layers=[2, 2, 2], seed=123)\n",
        "\n",
        "FNN = MultilayerPerceptronClassifier(labelCol=\"indexedLabel\", \\\n",
        "                                     featuresCol=\"indexedFeatures\",\\\n",
        "                                     maxIter=100, layers=layers, \\\n",
        "                                     blockSize=128, seed=1234)\n",
        "# Convert indexed labels back to original labels.\n",
        "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
        "                               labels=labelIndexer.labels)\n",
        "# Chain indexers and forest in a Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, FNN, labelConverter])\n",
        "# train the model\n",
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "dhTNIGUCK6XQ",
        "outputId": "18e8ba6d-db55-4f7b-d101-b146d9e96d18"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-8ee0ba0e4513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# mlp = MultilayerPerceptronClassifier(layers=[2, 2, 2], seed=123)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m FNN = MultilayerPerceptronClassifier(labelCol=\"indexedLabel\", \\\n\u001b[0m\u001b[1;32m     13\u001b[0m                                      \u001b[0mfeaturesCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"indexedFeatures\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                      \u001b[0mmaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MultilayerPerceptronClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "\n",
        "# Make predictions.\n",
        "predictions = model.transform(testData)\n",
        "# Select example rows to display.\n",
        "predictions.select(\"features\",\"label\",\"predictedLabel\").show(5)"
      ],
      "metadata": {
        "id": "us19N73XM0sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Predictions accuracy = %g, Test Error = %g\" % (accuracy,(1.0 - accuracy)))"
      ],
      "metadata": {
        "id": "Oz8JAsgaM2a0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}